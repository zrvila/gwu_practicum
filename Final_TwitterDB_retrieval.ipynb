{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83286d27-4f4f-44a1-a25f-cb836d68d450",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import datetime\n",
    "\n",
    "# Creating a SQL connection to our SQLite database\n",
    "con = sqlite3.connect(\"twitter.sqlite\")\n",
    "\n",
    "#store key screts for authentication\n",
    "consumer_key = \"1fjQSB7TQLPhhhGPz2PjQMEMz\"\n",
    "consumer_secret = \"fHO72DEe4vuw0m1fzJ7f89JpERSgUg4OA5sNKRCi0TO0IElXR0\"\n",
    "access_token = \"1487994957327749123-eBuh4zylO1WvMpGi8OWDIOclpMndJB\"\n",
    "access_token_secret = \"QbhohHu2bOfvLA9ElF4FSBS15vUiF8sRwbDFOZjo0UOn1\"\n",
    "\n",
    "#initialize authentication\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "\n",
    "#designate last tweet to append new tweets to database\n",
    "df = pd.read_sql('select * from twitter_table', con)\n",
    "last_id = df.Since_Id.max()\n",
    "\n",
    "#fetch mainstream tweets\n",
    "tweets = []\n",
    "likes = []\n",
    "time = []\n",
    "name = []\n",
    "dateid = []\n",
    "listm = {\n",
    "    'ABC', 'CBSNews', 'CNN', 'FoxNews', 'MSNBC', 'NBCNews', 'nytimes',\n",
    "    'USATODAY', 'WSJ', 'washingtonpost', 'politico', 'BGOV', 'nypost', 'Newsy',\n",
    "    'CNBC', 'nprpolitics', 'NewsHour', 'NewYorker', 'WIRED', 'voxdotcom',\n",
    "    'chicagotribune', 'UnivisionNews', 'BuzzFeedNews', 'Newsweek', 'usnews',\n",
    "    'thehill', 'AP', 'TheAtlantic', 'thedailybeast', 'EpochTimes', 'newsmax',\n",
    "    'latimes', 'BostonGlobe', 'TIME', 'dcexaminer', 'RollingStone', 'Slate',\n",
    "    'realDailyWire', 'dallasnews', 'VanityFair', 'townhallcom', 'TechCrunch',\n",
    "    'HeavySan', 'intelligencer', 'Inc', 'BlazeTV', 'StarTribune',\n",
    "    'ScienceMagazine', 'MashableNews', 'FortuneMagazine', 'Forbes',\n",
    "    'barronsonline', 'seattletimes', 'sciam', 'axios', 'SmithsonianMag',\n",
    "    'FiveThirtyEight', 'OANN', 'PhillyInquirer', 'TheCut', 'FastCompany', 'qz',\n",
    "    'MiamiHerald', 'statnews', 'sfchronicle', 'DailyCaller', 'WashTimes',\n",
    "    'theskimm', 'NRO', 'Deseret', 'FDRLST', 'TexasTribune', 'TheWeek',\n",
    "    'baltimoresun', 'TB_Times', 'TeenVogue', 'cspan', 'BreitbartNews',\n",
    "    'Newsday', 'TheAdvocateMag', 'theintercept', 'sltrib', 'TheRoot',\n",
    "    'Suntimes', 'propublica', 'HoustonChron', 'sdut', 'AmericanThinker',\n",
    "    'PopSci', 'reason', 'MotherJones', 'newsobserver', 'ForeignPolicy',\n",
    "    'MorningBrew', 'VICENews', 'readersdigest', 'reviewjournal', 'techreview',\n",
    "    'PunchbowlNews', 'thenation', 'bangordailynews', 'NorthBayNews',\n",
    "    'newrepublic', 'FreeBeacon', 'amconmag', 'ArkansasOnline', 'ScienceNews',\n",
    "    'PressHerald', 'csmonitor', 'cnsnews', 'CityJournal', 'Poynter',\n",
    "    'protocol', 'Harpers', 'TheSpectator', 'EconUS'\n",
    "}\n",
    "for key in listm:\n",
    "    j = tweepy.Cursor(\n",
    "        api.search_tweets,\n",
    "        q=\"<from:\" + key + \"> <covid OR sars-cov-2 OR chinavirus -RT> \",\n",
    "        since_id=last_id,\n",
    "        tweet_mode=\"extended\")\n",
    "    for i in j.items():\n",
    "        tweets.append(i.full_text)\n",
    "        likes.append(i.favorite_count)\n",
    "        time.append(i.created_at)\n",
    "        name.append(i.user.screen_name)\n",
    "        dateid.append(i.id)\n",
    "\n",
    "#write MS tweets to data frame\n",
    "df = pd.DataFrame({\n",
    "    \"Tweets\": tweets,\n",
    "    \"Likes\": likes,\n",
    "    \"Time\": time,\n",
    "    \"Name\": name,\n",
    "    \"Since_Id\": dateid\n",
    "})\n",
    "df['Source Type'] = pd.Series([\"Mainstream\" for x in range(len(df.index))])\n",
    "\n",
    "# Appending pandas dataframe to sql database\n",
    "df.to_sql('twitter_table', con, index=False, if_exists='append')\n",
    "\n",
    "#fetch politician tweets\n",
    "tweets = []\n",
    "likes = []\n",
    "time = []\n",
    "name = []\n",
    "dateid = []\n",
    "listp = {\n",
    "    'SenTedCruz', 'SenatorHagerty', 'JohnCornyn', 'AlexPadilla4CA',\n",
    "    'marcorubio', 'MarshaBlackburn', 'SenatorDurbin', 'SenatorShaheen',\n",
    "    'SenJeffMerkley', 'senrobportman', 'RepCasten', 'RepTedLieu',\n",
    "    'RepDonBacon', 'RepJennif', 'RepBoebert', 'RepChipRoy', 'RepTimBurchett',\n",
    "    'RepJayapal', 'RepMTG', 'RepMattGaetz', 'AOC', 'RepCawthorn'\n",
    "}\n",
    "for key in listp:\n",
    "    j = tweepy.Cursor(\n",
    "        api.search_tweets,\n",
    "        q=\"<from:\" + key + \"> <covid OR sars-cov-2 OR chinavirus -RT> \",\n",
    "        since_id=last_id,\n",
    "        tweet_mode=\"extended\")\n",
    "    for i in j.items():\n",
    "        tweets.append(i.full_text)\n",
    "        likes.append(i.favorite_count)\n",
    "        time.append(i.created_at)\n",
    "        name.append(i.user.screen_name)\n",
    "        dateid.append(i.id)\n",
    "\n",
    "#write POLIT tweets to data frame\n",
    "df = pd.DataFrame({\n",
    "    \"Tweets\": tweets,\n",
    "    \"Likes\": likes,\n",
    "    \"Time\": time,\n",
    "    \"Name\": name,\n",
    "    \"Since_Id\": dateid\n",
    "})\n",
    "df['Source Type'] = pd.Series([\"Politicians\" for x in range(len(df.index))])\n",
    "\n",
    "# Appending pandas dataframe to sql database\n",
    "df.to_sql('twitter_table', con, index=False, if_exists='append')\n",
    "\n",
    "#fetch scientific tweets\n",
    "tweets = []\n",
    "likes = []\n",
    "time = []\n",
    "name = []\n",
    "dateid = []\n",
    "\n",
    "st = tweepy.Cursor(\n",
    "    api.search_tweets,\n",
    "    q=\"<from:CDCgov OR from:NIH> <covid OR sars-cov-2 OR chinavirus -RT> \",\n",
    "    since_id=last_id,\n",
    "    tweet_mode=\"extended\")\n",
    "\n",
    "for i in st.items():\n",
    "    tweets.append(i.full_text)\n",
    "    likes.append(i.favorite_count)\n",
    "    time.append(i.created_at)\n",
    "    name.append(i.user.screen_name)\n",
    "    dateid.append(i.id)\n",
    "\n",
    "#write SCI tweets to data frame\n",
    "df = pd.DataFrame({\n",
    "    \"Tweets\": tweets,\n",
    "    \"Likes\": likes,\n",
    "    \"Time\": time,\n",
    "    \"Name\": name,\n",
    "    \"Since_Id\": dateid\n",
    "})\n",
    "df['Source Type'] = pd.Series([\"Scientific\" for x in range(len(df.index))])\n",
    "\n",
    "# Appending pandas dataframe to sql database\n",
    "df.to_sql('twitter_table', con, index=False, if_exists='append')\n",
    "\n",
    "#fetch fringe tweets\n",
    "tweets = []\n",
    "likes = []\n",
    "time = []\n",
    "name = []\n",
    "dateid = []\n",
    "listm = {\n",
    "    'joerogan', 'TPUSA', 'Timcast', 'MsBlaireWhite', 'TheOfficerTatum',\n",
    "    'KeithOlbermann', 'hodgetwins', 'DrunkenPeasants', 'InnuendoStudios',\n",
    "    'hasanthehun', 'TheOmniLiberal', 'ContraPoints', 'MarkDice',\n",
    "    'KyleKulinski', 'TheLaurenChen', 'MattWalshBlog', 'andrewklavan',\n",
    "    'Lauren_Southern', 'PhillyD', 'jordanbpeterson', 'dpakman', 'SamHarrisOrg',\n",
    "    'jimmy_dore', 'majorityfm', 'rustyrockets', 'RudyGiuliani', 'AnnCoulter',\n",
    "    'TheQuartering', 'SaltyCracker9', 'LiberalHivemind', 'DineshDSouza',\n",
    "    'ANTHONYBLOGAN', 'VaushV', 'LeeCamp', 'amtvmedia', 'AydinPaladin',\n",
    "    'AwakenWithJP', 'DiamondandSilk', 'TheYoungTurks', 'democracynow',\n",
    "    'RealAmVoice', 'Suspended', 'BlacklistedNews', 'news_ntd', 'TonyBrunoShow',\n",
    "    'WayneDupreeShow', 'JoeTalkShow', 'monicaonairtalk', 'ResisttheMS',\n",
    "    'Breaking911', 'RSBNetwork', 'JustTheNews', 'TheDamaniFelder', 'hotair',\n",
    "    'LifeNewsHQ', 'RebelNewsOnline', 'MalcolmOutLoud', 'SiriusXMPatriot',\n",
    "    'MediaRightNews', 'Leeroypress', 'twitchy', 'DschlopeisBack',\n",
    "    'VillageNorth', 'richardursomd', 'ajeemontes', 'CRRJA5', 'zerohedge',\n",
    "    'tspooky', 'ROHLL5', 'carlossimancas', 'ivoryhecker', 'William5849',\n",
    "    'Dloesch', 'LadyRedWave', 'Gonewiththerain', 'RealStewPeters',\n",
    "    'bigleaguepol', 'SteveGruber', 'tweettruth2me', 'chiefnerd',\n",
    "    'DavidJHarrisJr', 'mythinformedmke', 'brandonstraka', 'joeysalads',\n",
    "    'realmattcouch', 'serremmy', 'redvoicemedia', 'mikhailaaleksis',\n",
    "    'jasonmillerindc', 'childrensHD', 'barbiewakeupusa'\n",
    "}\n",
    "for key in listm:\n",
    "    j = tweepy.Cursor(\n",
    "        api.search_tweets,\n",
    "        q=\"<from:\" + key + \"> <covid OR sars-cov-2 OR chinavirus -RT> \",\n",
    "        since_id=last_id,\n",
    "        tweet_mode=\"extended\")\n",
    "    for i in j.items():\n",
    "        tweets.append(i.full_text)\n",
    "        likes.append(i.favorite_count)\n",
    "        time.append(i.created_at)\n",
    "        name.append(i.user.screen_name)\n",
    "        dateid.append(i.id)\n",
    "\n",
    "#write fringe tweets to dataframe\n",
    "df = pd.DataFrame({\n",
    "    \"Tweets\": tweets,\n",
    "    \"Likes\": likes,\n",
    "    \"Time\": time,\n",
    "    \"Name\": name,\n",
    "    \"Since_Id\": dateid\n",
    "})\n",
    "df['Source Type'] = pd.Series([\"Fringe\" for x in range(len(df.index))])\n",
    "\n",
    "# Appending pandas dataframe to sql database\n",
    "df.to_sql('twitter_table', con, index=False, if_exists='append')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
